# # backend/ocr.py
# import os, re
# import numpy as np
# import cv2
# from paddleocr import PaddleOCR

# # ---------------------------
# # ì „ì—­ íŠœë‹ í¬ì¸íŠ¸ (ìˆ«ìë§Œ ë°”ê¿”ê°€ë©° ì‹œí—˜)
# # ---------------------------
# TUNE = {
#     "det_db_box_thresh": 0.40,     # [0.30~0.60] ë‚®ì¶”ë©´ ì‘ì€ ê¸€ìâ†‘(ì¡ìŒâ†‘)
#     "det_db_unclip_ratio": 2.0,    # [1.6~2.2] ë°•ìŠ¤ ì—¬ìœ 
#     "det_limit_side_len": 1920,    # [1280~1920] ê¸¸ìˆ˜ë¡ ì •í™•â†‘/ëŠë¦¼â†‘
#     "max_text_length": 96,         # [64~128] ê¸´ ë¼ë²¨ì´ë©´ â†‘
#     "upscale_factor": 1.7,         # [1.4~1.8] ë©€í‹°íŒ¨ìŠ¤ ì—…ìŠ¤ì¼€ì¼
#     "use_binary_second_pass": True,
#     "rotate_degrees": [0, 180, 90, 270],  # ë°©í–¥ ë¶ˆì•ˆì • ì‹œ ìœ ìš©
#     "tile_refine_upscale": 2.0,    # ë°•ìŠ¤ë³„ ì¬ì¸ì‹ ì—…ìŠ¤ì¼€ì¼
# }

# # ---------------------------
# # ì„œë²„ ëª¨ë¸(ëŒ€í˜•) ì‚¬ìš© ì˜µì…˜
# #  - í™˜ê²½ë³€ìˆ˜ë‚˜ ê²½ë¡œê°€ ìˆìœ¼ë©´ ìë™ ì‚¬ìš©
# # ---------------------------
# USE_SERVER_MODELS = True
# DET_DIR = os.getenv("PPOCR_DET_DIR", "").strip()      # ì˜ˆ: ./models/ch_ppocr_server_v2.0_det_infer
# REC_DIR = os.getenv("PPOCR_REC_DIR", "").strip()      # ì˜ˆ: ./models/korean_PP-OCRv4_server_rec_infer
# CLS_DIR = os.getenv("PPOCR_CLS_DIR", "").strip()      # (ì„ íƒ)

# OCR_KW = dict(
#     use_angle_cls=True,
#     lang="korean",
#     det_db_box_thresh=TUNE["det_db_box_thresh"],
#     det_db_unclip_ratio=TUNE["det_db_unclip_ratio"],
#     det_limit_side_len=TUNE["det_limit_side_len"],
#     max_text_length=TUNE["max_text_length"],
#     show_log=False,
# )

# if USE_SERVER_MODELS and DET_DIR and REC_DIR:
#     OCR_KW.update({
#         "det_model_dir": DET_DIR,
#         "rec_model_dir": REC_DIR,
#     })
#     if CLS_DIR:
#         OCR_KW["cls_model_dir"] = CLS_DIR

# _ocr = PaddleOCR(**OCR_KW)


# # ---------------------------
# # ë³´ì¡°: íŒŒì‹±/ì´ì§„í™”/ì—…ìŠ¤ì¼€ì¼
# # ---------------------------
# def _parse_result(result):
#     lines, boxes = [], []
#     if not result:
#         return "", [], 0.0
#     for page in result or []:
#         if not page: 
#             continue
#         for it in page:
#             try:
#                 if isinstance(it, (list, tuple)) and len(it) == 2:
#                     pts, data = it
#                     if not pts or len(pts) != 4: 
#                         continue
#                     txt, conf = "", 0.0
#                     if isinstance(data, (list, tuple)) and len(data) >= 2:
#                         txt, conf = data[0], float(data[1])
#                     elif isinstance(data, dict):
#                         txt = data.get("text", "")
#                         conf = float(data.get("score", 0.0))
#                     P = []
#                     for p in pts:
#                         if isinstance(p, (list, tuple)) and len(p) == 2:
#                             P.append([float(p[0]), float(p[1])])
#                     if len(P) != 4: 
#                         continue
#                     boxes.append({"text": txt or "", "conf": conf, "box": P})
#                     if txt: 
#                         lines.append(txt)
#             except Exception:
#                 continue
#     mean_conf = float(np.mean([b["conf"] for b in boxes])) if boxes else 0.0
#     return "\n".join(lines).strip(), boxes, mean_conf

# def _run_once(image_bgr):
#     res = _ocr.ocr(image_bgr, cls=True)
#     return _parse_result(res)

# def _binarize(img):
#     g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
#     g = cv2.GaussianBlur(g, (3,3), 0)
#     _, th = cv2.threshold(g, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
#     return cv2.cvtColor(th, cv2.COLOR_GRAY2BGR)

# def _best_of(candidates):
#     best = ("", [], 0.0)
#     for im in candidates:
#         t, b, m = _run_once(im)
#         if (m > best[2]) or (m == best[2] and len(t) > len(best[0])):
#             best = (t, b, m)
#     return best


# # ---------------------------
# # í•µì‹¬1: ì „ì²´ ì´ë¯¸ì§€ ë©€í‹°íŒ¨ìŠ¤ (íšŒì „/ì—…ìŠ¤ì¼€ì¼/ì´ì§„í™”)
# # ---------------------------
# def run_ocr(image_bgr):
#     cand = []
#     for deg in TUNE["rotate_degrees"]:
#         im = image_bgr if deg == 0 else np.ascontiguousarray(np.rot90(image_bgr, k=deg//90))
#         cand.append(im)
#         if TUNE["use_binary_second_pass"]:
#             cand.append(_binarize(im))
#         uf = TUNE["upscale_factor"]
#         if uf and uf > 1.0:
#             h, w = im.shape[:2]
#             up = cv2.resize(im, (int(w*uf), int(h*uf)), interpolation=cv2.INTER_CUBIC)
#             cand.append(up)

#     text, boxes, mean_conf = _best_of(cand)

#     # í•µì‹¬2: ë°•ìŠ¤ë³„ íƒ€ì¼ ì¬ì¸ì‹ (í¬ë¡­â†’ì—…ìŠ¤ì¼€ì¼â†’ì´ì§„í™”)
#     if boxes:
#         improved = []
#         H, W = image_bgr.shape[:2]
#         scale_up = TUNE["tile_refine_upscale"]
#         for b in boxes:
#             pts = np.array(b["box"], dtype=np.float32)
#             x1 = max(int(np.min(pts[:,0]))-2, 0)
#             y1 = max(int(np.min(pts[:,1]))-2, 0)
#             x2 = min(int(np.max(pts[:,0]))+2, W-1)
#             y2 = min(int(np.max(pts[:,1]))+2, H-1)
#             crop = image_bgr[y1:y2+1, x1:x2+1]
#             if crop.size < 10: 
#                 improved.append(b); 
#                 continue

#             tiles = [crop]
#             if scale_up and scale_up > 1.0:
#                 ch, cw = crop.shape[:2]
#                 tiles.append(cv2.resize(crop, (int(cw*scale_up), int(ch*scale_up)), interpolation=cv2.INTER_CUBIC))
#             if TUNE["use_binary_second_pass"]:
#                 tiles += [_binarize(t) for t in list(tiles)]

#             # ì¸ì‹ì€ crop ë‹¨ìœ„ì—ì„œë§Œ: detì€ ë¶ˆí•„ìš”í•˜ë¯€ë¡œ ê·¸ëŒ€ë¡œ _run_once ì‚¬ìš©(ê³¼ê°íˆ)
#             best_txt, best_conf = b["text"], b["conf"]
#             for timg in tiles:
#                 # ì¸ì‹ë§Œ í•˜ê³  ì‹¶ì§€ë§Œ API ì œì•½ìƒ ì „ì²´ë¡œ ëŒë¦¼ â†’ cropì´ ì‘ì•„ ë¶€ë‹´ ì ìŒ
#                 tt, bb, mm = _run_once(timg)
#                 # cropì—ì„œ ë‚˜ì˜¤ëŠ” ì²« ë¬¸ìì—´ë§Œ ì·¨í•¨
#                 if tt and (mm >= best_conf or (abs(mm-best_conf) < 1e-3 and len(tt) > len(best_txt))):
#                     best_txt, best_conf = tt, mm
#             improved.append({**b, "text": best_txt, "conf": float(best_conf)})
#         boxes = improved
#         # ì „ì²´ í…ìŠ¤íŠ¸ë„ ë°•ìŠ¤ ìˆœìœ¼ë¡œ ì¬êµ¬ì„±
#         text = " ".join([re.sub(r"\s+", " ", b["text"]).strip() for b in boxes if b["text"]]).strip()

#     # í•µì‹¬3: í˜¼ë™ ë¬¸ì ë³´ì • + ê·œì¹™ í›„ì²˜ë¦¬
#     text, boxes = _postprocess(text, boxes)
#     return text, boxes


# # ---------------------------
# # í›„ì²˜ë¦¬(í˜¼ë™ ë³´ì •/ê·œì¹™)
# # ---------------------------
# CONFUSION_MAP = str.maketrans({
#     "ï¼":"0","ï¼‘":"1","ï¼’":"2","ï¼“":"3","ï¼”":"4","ï¼•":"5","ï¼–":"6","ï¼—":"7","ï¼˜":"8","ï¼™":"9",
#     "O":"0","o":"0","S":"5","s":"5","I":"1","l":"1","B":"8","Z":"2",
# })

# def _fix_confusions(s: str) -> str:
#     s2 = s.translate(CONFUSION_MAP)
#     # ì—°ì† íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
#     s2 = re.sub(r"[|]{2,}", "||", s2)
#     return s2

# def _apply_domain_rules(s: str) -> str:
#     # Wi-Fi SSID/PASS íŒ¨í„´ êµì • ì˜ˆì‹œ
#     s = re.sub(r"\bP[Aa][Ss][Ss]\b", "PASS", s)
#     s = re.sub(r"\b[S5]{2}[Ii1][Dd]\b", "SSID", s)
#     return s

# def _postprocess(text, boxes):
#     text = _fix_confusions(text)
#     text = _apply_domain_rules(text)
#     new_boxes = []
#     for b in boxes:
#         t = _apply_domain_rules(_fix_confusions(b["text"] or ""))
#         new_boxes.append({**b, "text": t})
#     return text, new_boxes


# # ---------------------------
# # ì…€(ì¡°ê°) ë¦¬ìŠ¤íŠ¸ OCR
# # ---------------------------
# def run_ocr_on_list(images_bgr):
#     texts, all_boxes = [], []
#     for im in images_bgr:
#         t, b = run_ocr(im)
#         if t:
#             texts.append(t)
#         all_boxes.extend(b)
#     return " ".join(texts).strip(), all_boxes

# backend/ocr.py
import os, re
import numpy as np
import cv2
from paddleocr import PaddleOCR

# ---------------------------
# ì „ì—­ íŠœë‹ í¬ì¸íŠ¸
# ---------------------------
TUNE = {
    "det_db_thresh": 0.30,          # ğŸ”¹ í…ìŠ¤íŠ¸ vs ë°°ê²½ ì„ê³„ (ì¶”ê°€)
    "det_db_box_thresh": 0.50,      # ğŸ”¹ ë°•ìŠ¤ í™•ì • ì„ê³„
    "det_db_unclip_ratio": 2.1,     # ğŸ”¹ ë°•ìŠ¤ ì—¬ìœ 
    "det_limit_side_len": 1920,     # ğŸ”¹ ê²€ì¶œ í•´ìƒë„ ìƒí•œ
    "rec_image_shape": "3,48,320",  # ğŸ”¹ ì¸ì‹ ì…ë ¥ í¬ê¸°(ì¤„ ë†’ì´â†‘)
    "max_text_length": 96,          # ğŸ”¹ ê¸´ ë¼ë²¨ ëŒ€ë¹„
    "drop_score": 0.30,             # ğŸ”¹ ë„ˆë¬´ ë‚®ì€ ê²°ê³¼ ì œê±°
    "upscale_factor": 1.6,          # ğŸ”¹ ì „ì²´ ì—…ìŠ¤ì¼€ì¼ í›„ë³´
    "use_binary_second_pass": True,  # ğŸ”¹ Otsu ì´ì§„í™” 2nd pass
    "use_sauvola": True,            # ğŸ”¹ Sauvola ì ì‘ ì´ì§„í™” í›„ë³´
    "rotate_degrees": [0, 180, 90, 270],  # ğŸ”¹ íšŒì „ TTA
    "tile_refine_upscale": 2.0,     # ğŸ”¹ ë°•ìŠ¤ë³„ ì¬ì¸ì‹ ì—…ìƒ˜í”Œ
}

# ---------------------------
# ì„œë²„ ëª¨ë¸(ëŒ€í˜•) ì‚¬ìš©
# ---------------------------
USE_SERVER_MODELS = True
DET_DIR = os.getenv("PPOCR_DET_DIR", "").strip()
REC_DIR = os.getenv("PPOCR_REC_DIR", "").strip()
CLS_DIR = os.getenv("PPOCR_CLS_DIR", "").strip()

OCR_KW = dict(
    use_angle_cls=True,
    lang="korean",
    det_db_thresh=TUNE["det_db_thresh"],
    det_db_box_thresh=TUNE["det_db_box_thresh"],
    det_db_unclip_ratio=TUNE["det_db_unclip_ratio"],
    det_limit_side_len=TUNE["det_limit_side_len"],
    rec_image_shape=TUNE["rec_image_shape"],
    max_text_length=TUNE["max_text_length"],
    drop_score=TUNE["drop_score"],
    show_log=False,
)

if USE_SERVER_MODELS and DET_DIR and REC_DIR:
    OCR_KW.update({
        "det_model_dir": DET_DIR,
        "rec_model_dir": REC_DIR,
    })
    if CLS_DIR:
        OCR_KW["cls_model_dir"] = CLS_DIR

_ocr = PaddleOCR(**OCR_KW)

# ---------------------------
# ë³´ì¡°: íŒŒì‹±/ì´ì§„í™”/ì—…ìŠ¤ì¼€ì¼
# ---------------------------
def _parse_result(result):
    lines, boxes = [], []
    if not result:
        return "", [], 0.0
    for page in result or []:
        if not page:
            continue
        for it in page:
            try:
                if isinstance(it, (list, tuple)) and len(it) == 2:
                    pts, data = it
                    if not pts or len(pts) != 4:
                        continue
                    txt, conf = "", 0.0
                    if isinstance(data, (list, tuple)) and len(data) >= 2:
                        txt, conf = data[0], float(data[1])
                    elif isinstance(data, dict):
                        txt = data.get("text", "")
                        conf = float(data.get("score", 0.0))
                    P = []
                    for p in pts:
                        if isinstance(p, (list, tuple)) and len(p) == 2:
                            P.append([float(p[0]), float(p[1])])
                    if len(P) != 4:
                        continue
                    boxes.append({"text": txt or "", "conf": conf, "box": P})
                    if txt:
                        lines.append(txt)
            except Exception:
                continue
    mean_conf = float(np.mean([b["conf"] for b in boxes])) if boxes else 0.0
    return "\n".join(lines).strip(), boxes, mean_conf

def _run_once(image_bgr):
    res = _ocr.ocr(image_bgr, cls=True)
    return _parse_result(res)

def _binarize_otsu(img):
    g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    g = cv2.GaussianBlur(g, (3,3), 0)
    _, th = cv2.threshold(g, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
    return cv2.cvtColor(th, cv2.COLOR_GRAY2BGR)

def _binarize_sauvola(img):
    # skimage ì—†ì´ OpenCV ì ì‘ì´ì§„ìœ¼ë¡œ ê·¼ì‚¬ (ê°„í¸/ê²½ëŸ‰)
    g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    g = cv2.GaussianBlur(g, (3,3), 0)
    win = max(25, int(min(g.shape[:2]) * 0.035)//2*2+1)
    th = cv2.adaptiveThreshold(g, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                               cv2.THRESH_BINARY, win, 10)
    return cv2.cvtColor(th, cv2.COLOR_GRAY2BGR)

def _contrast_boost(img):
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.2, tileGridSize=(8,8))
    l2 = clahe.apply(l)
    out = cv2.cvtColor(cv2.merge([l2, a, b]), cv2.COLOR_LAB2BGR)
    blur = cv2.GaussianBlur(out, (0,0), 1.0)
    sharp = cv2.addWeighted(out, 1.4, blur, -0.4, 0)
    return sharp

def _best_of(candidates):
    best = ("", [], 0.0, "raw")
    for im, tag in candidates:
        t, b, m = _run_once(im)
        # ìš°ì„ ìˆœìœ„: mean_conf > ê¸¸ì´
        if (m > best[2]) or (abs(m - best[2]) < 1e-6 and len(t) > len(best[0])):
            best = (t, b, m, tag)
    return best  # (text, boxes, mean_conf, variant)

# ---------------------------
# í•µì‹¬: ë©€í‹°íŒ¨ìŠ¤(TTA) + ë°•ìŠ¤ ì¬ì¸ì‹ + í›„ì²˜ë¦¬
# ---------------------------
def run_ocr(image_bgr):
    cand = []
    base = _contrast_boost(image_bgr)

    for deg in TUNE["rotate_degrees"]:
        im = base if deg == 0 else np.ascontiguousarray(np.rot90(base, k=deg//90))
        # ì›ë³¸
        cand.append((im, f"enh_rot{deg}"))

        # ì—…ìŠ¤ì¼€ì¼
        uf = TUNE["upscale_factor"]
        if uf and uf > 1.0:
            h, w = im.shape[:2]
            up = cv2.resize(im, (int(w*uf), int(h*uf)), interpolation=cv2.INTER_CUBIC)
            cand.append((up, f"enh_up{uf}_rot{deg}"))

        # ì´ì§„í™” 2ì¢…
        if TUNE["use_binary_second_pass"]:
            cand.append((_binarize_otsu(im), f"otsu_rot{deg}"))
        if TUNE["use_sauvola"]:
            cand.append((_binarize_sauvola(im), f"sauvola_rot{deg}"))

    text, boxes, mean_conf, variant = _best_of(cand)

    # ë°•ìŠ¤ë³„ íƒ€ì¼ ì¬ì¸ì‹
    if boxes:
        improved = []
        H, W = image_bgr.shape[:2]
        scale_up = TUNE["tile_refine_upscale"]
        for b in boxes:
            pts = np.array(b["box"], dtype=np.float32)
            x1 = max(int(np.min(pts[:,0]))-2, 0)
            y1 = max(int(np.min(pts[:,1]))-2, 0)
            x2 = min(int(np.max(pts[:,0]))+2, W-1)
            y2 = min(int(np.max(pts[:,1]))+2, H-1)
            crop = image_bgr[y1:y2+1, x1:x2+1]
            if crop.size < 10:
                improved.append(b); continue

            tiles = [crop]
            if scale_up and scale_up > 1.0:
                ch, cw = crop.shape[:2]
                tiles.append(cv2.resize(crop, (int(cw*scale_up), int(ch*scale_up)), interpolation=cv2.INTER_CUBIC))
            if TUNE["use_binary_second_pass"]:
                tiles += [_binarize_otsu(t) for t in list(tiles)]
            if TUNE["use_sauvola"]:
                tiles += [_binarize_sauvola(t) for t in list(tiles)]

            best_txt, best_conf = b["text"], b["conf"]
            for timg in tiles:
                tt, bb, mm = _run_once(timg)
                if tt and (mm >= best_conf or (abs(mm-best_conf) < 1e-3 and len(tt) > len(best_txt))):
                    best_txt, best_conf = tt, mm
            improved.append({**b, "text": best_txt, "conf": float(best_conf)})
        boxes = improved
        # ì „ì²´ í…ìŠ¤íŠ¸ ì¬êµ¬ì„±
        text = " ".join([re.sub(r"\s+", " ", b["text"]).strip() for b in boxes if b["text"]]).strip()
        # ìµœì¢… mean_conf ì¬ê³„ì‚°
        mean_conf = float(np.mean([b["conf"] for b in boxes])) if boxes else mean_conf
        variant = variant + "+tile"

    # í›„ì²˜ë¦¬(í˜¼ë™/ë„ë©”ì¸ ê·œì¹™)
    text, boxes = _postprocess(text, boxes)
    return text, boxes, float(mean_conf), variant

# ---------------------------
# í›„ì²˜ë¦¬
# ---------------------------
CONFUSION_MAP = str.maketrans({
    "ï¼":"0","ï¼‘":"1","ï¼’":"2","ï¼“":"3","ï¼”":"4","ï¼•":"5","ï¼–":"6","ï¼—":"7","ï¼˜":"8","ï¼™":"9",
    "O":"0","o":"0","S":"5","s":"5","I":"1","l":"1","B":"8","Z":"2",
})

def _fix_confusions(s: str) -> str:
    s2 = s.translate(CONFUSION_MAP)
    s2 = re.sub(r"[|]{2,}", "||", s2)
    return s2

def _apply_domain_rules(s: str) -> str:
    s = re.sub(r"\bP[Aa][Ss][Ss]\b", "PASS", s)
    s = re.sub(r"\b[S5]{2}[Ii1][Dd]\b", "SSID", s)
    return s

def _postprocess(text, boxes):
    text = _apply_domain_rules(_fix_confusions(text))
    new_boxes = []
    for b in boxes:
        t = _apply_domain_rules(_fix_confusions(b["text"] or ""))
        new_boxes.append({**b, "text": t})
    return text, new_boxes

# ---------------------------
# ì…€(ì¡°ê°) ë¦¬ìŠ¤íŠ¸ OCR (í˜¸í™˜)
# ---------------------------
def run_ocr_on_list(images_bgr):
    texts, all_boxes, confs, variants = [], [], [], []
    for im in images_bgr:
        res = run_ocr(im)
        # (text, boxes, mean_conf, variant)
        t, b = res[0], res[1]
        texts.append(t) if t else None
        all_boxes.extend(b)
        if len(res) >= 3: confs.append(float(res[2]))
        if len(res) >= 4: variants.append(str(res[3]))
    text_join = " ".join([t for t in texts if t]).strip()
    mean_conf = float(np.mean(confs)) if confs else 0.0
    variant = variants[0] if variants else "raw"
    return text_join, all_boxes, mean_conf, variant
